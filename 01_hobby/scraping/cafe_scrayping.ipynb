{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78bdce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "class Tabelog:\n",
    "    \"\"\"\n",
    "    食べログスクレイピングクラス\n",
    "    test_mode=Trueで動作させると、最初のページの３店舗のデータのみを取得できる\n",
    "    \"\"\"\n",
    "    def __init__(self, base_url, test_mode=False, p_ward='東京都内', begin_page=1, end_page=30):\n",
    "\n",
    "        # 変数宣言\n",
    "        self.store_id = ''\n",
    "        self.store_id_num = 0\n",
    "        self.store_name = ''\n",
    "        self.score = 0\n",
    "        self.ward = p_ward\n",
    "        self.review_cnt = 0\n",
    "        self.review = ''\n",
    "        self.columns = ['store_id', 'store_name', 'score', 'ward', 'review_cnt', 'review']\n",
    "        self.df = pd.DataFrame(columns=self.columns)\n",
    "        self.__regexcomp = re.compile(r'\\n|\\s') # \\nは改行、\\sは空白\n",
    "\n",
    "        page_num = begin_page # 店舗一覧ページ番号\n",
    "\n",
    "        if test_mode:\n",
    "            list_url = base_url + str(page_num) +  '/?Srt=D&SrtT=rt&sort_mode=1' #食べログの点数ランキングでソートする際に必要な処理\n",
    "            self.scrape_list(list_url, mode=test_mode)\n",
    "        else:\n",
    "            while True:\n",
    "                list_url = base_url + str(page_num) +  '/?Srt=D&SrtT=rt&sort_mode=1' #食べログの点数ランキングでソートする際に必要な処理\n",
    "                if self.scrape_list(list_url, mode=test_mode) != True:\n",
    "                    break\n",
    "\n",
    "                # INパラメータまでのページ数データを取得する\n",
    "                if page_num >= end_page:\n",
    "                    break\n",
    "                page_num += 1\n",
    "        return\n",
    "\n",
    "    def scrape_list(self, list_url, mode):\n",
    "        \"\"\"\n",
    "        店舗一覧ページのパーシング\n",
    "        \"\"\"\n",
    "        r = requests.get(list_url)\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            return False\n",
    "\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        soup_a_list = soup.find_all('a', class_='list-rst__rst-name-target') # 店名一覧\n",
    "\n",
    "        if len(soup_a_list) == 0:\n",
    "            return False\n",
    "\n",
    "        if mode:\n",
    "            for soup_a in soup_a_list[:2]:\n",
    "                item_url = soup_a.get('href') # 店の個別ページURLを取得\n",
    "                self.store_id_num += 1\n",
    "                self.scrape_item(item_url, mode)\n",
    "        else:\n",
    "            for soup_a in soup_a_list:\n",
    "                item_url = soup_a.get('href') # 店の個別ページURLを取得\n",
    "                self.store_id_num += 1\n",
    "                self.scrape_item(item_url, mode)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def scrape_item(self, item_url, mode):\n",
    "        \"\"\"\n",
    "        個別店舗情報ページのパーシング\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "\n",
    "        r = requests.get(item_url)\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            print(f'error:not found{ item_url }')\n",
    "            return\n",
    "\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "        # 店舗名称取得\n",
    "        # <h2 class=\"display-name\">\n",
    "        #     <span>\n",
    "        #         麺匠　竹虎 新宿店\n",
    "        #     </span>\n",
    "        # </h2>\n",
    "        store_name_tag = soup.find('h2', class_='display-name')\n",
    "        store_name = store_name_tag.span.string\n",
    "        print('{}→店名：{}'.format(self.store_id_num, store_name.strip()), end='')\n",
    "        self.store_name = store_name.strip()\n",
    "\n",
    "        # ラーメン屋、つけ麺屋以外の店舗は除外\n",
    "        store_head = soup.find('div', class_='rdheader-subinfo') # 店舗情報のヘッダー枠データ取得\n",
    "        store_head_list = store_head.find_all('dl')\n",
    "        store_head_list = store_head_list[1].find_all('span')\n",
    "        #print('ターゲット：', store_head_list[0].text)\n",
    "\n",
    "#         if store_head_list[0].text not in {'ラーメン', 'つけ麺'}:\n",
    "#             print('ラーメンorつけ麺のお店ではないので処理対象外')\n",
    "#             self.store_id_num -= 1\n",
    "#             return\n",
    "\n",
    "        # 評価点数取得\n",
    "        #<b class=\"c-rating__val rdheader-rating__score-val\" rel=\"v:rating\">\n",
    "        #    <span class=\"rdheader-rating__score-val-dtl\">3.58</span>\n",
    "        #</b>\n",
    "        rating_score_tag = soup.find('b', class_='c-rating__val')\n",
    "        rating_score = rating_score_tag.span.string\n",
    "        print('  評価点数：{}点'.format(rating_score), end='')\n",
    "        self.score = rating_score\n",
    "\n",
    "        # 評価点数が存在しない店舗は除外\n",
    "        if rating_score == '-':\n",
    "            print('  評価がないため処理対象外')\n",
    "            self.store_id_num -= 1\n",
    "            return\n",
    "       # 評価が3.5未満店舗は除外\n",
    "        if float(rating_score) < 3.5:\n",
    "            print('  食べログ評価が3.5未満のため処理対象外')\n",
    "            self.store_id_num -= 1\n",
    "            return\n",
    "\n",
    "        # レビュー一覧URL取得\n",
    "        #<a class=\"mainnavi\" href=\"https://tabelog.com/tokyo/A1304/A130401/13143442/dtlrvwlst/\"><span>口コミ</span><span class=\"rstdtl-navi__total-count\"><em>60</em></span></a>\n",
    "        review_tag_id = soup.find('li', id=\"rdnavi-review\")\n",
    "        review_tag = review_tag_id.a.get('href')\n",
    "\n",
    "        # レビュー件数取得\n",
    "        print('  レビュー件数：{}'.format(review_tag_id.find('span', class_='rstdtl-navi__total-count').em.string), end='')\n",
    "        self.review_cnt = review_tag_id.find('span', class_='rstdtl-navi__total-count').em.string\n",
    "\n",
    "        # レビュー一覧ページ番号\n",
    "        page_num = 1 #1ページ*20 = 20レビュー 。この数字を変えて取得するレビュー数を調整。\n",
    "\n",
    "        # レビュー一覧ページから個別レビューページを読み込み、パーシング\n",
    "        # 店舗の全レビューを取得すると、食べログの評価ごとにデータ件数の濃淡が発生してしまうため、\n",
    "        # 取得するレビュー数は１ページ分としている（件数としては１ページ*20=２0レビュー）\n",
    "        while True:\n",
    "            review_url = review_tag + 'COND-0/smp1/?lc=0&rvw_part=all&PG=' + str(page_num)\n",
    "            #print('\\t口コミ一覧リンク：{}'.format(review_url))\n",
    "            print(' . ' , end='') #LOG\n",
    "            if self.scrape_review(review_url) != True:\n",
    "                break\n",
    "            if page_num >= 1:\n",
    "                break\n",
    "            page_num += 1\n",
    "\n",
    "        process_time = time.time() - start\n",
    "        print('  取得時間：{}'.format(process_time))\n",
    "\n",
    "        return\n",
    "\n",
    "    def scrape_review(self, review_url):\n",
    "        \"\"\"\n",
    "        レビュー一覧ページのパーシング\n",
    "        \"\"\"\n",
    "        r = requests.get(review_url)\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            print(f'error:not found{ review_url }')\n",
    "            return False\n",
    "\n",
    "        # 各個人の口コミページ詳細へのリンクを取得する\n",
    "        #<div class=\"rvw-item js-rvw-item-clickable-area\" data-detail-url=\"/tokyo/A1304/A130401/13141542/dtlrvwlst/B408082636/?use_type=0&amp;smp=1\">\n",
    "        #</div>\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        review_url_list = soup.find_all('div', class_='rvw-item') # 口コミ詳細ページURL一覧\n",
    "\n",
    "        if len(review_url_list) == 0:\n",
    "            return False\n",
    "\n",
    "        for url in review_url_list:\n",
    "            review_detail_url = 'https://tabelog.com' + url.get('data-detail-url')\n",
    "            #print('\\t口コミURL：', review_detail_url)\n",
    "\n",
    "            # 口コミのテキストを取得\n",
    "            self.get_review_text(review_detail_url)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def get_review_text(self, review_detail_url):\n",
    "        \"\"\"\n",
    "        口コミ詳細ページをパーシング\n",
    "        \"\"\"\n",
    "        r = requests.get(review_detail_url)\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            print(f'error:not found{ review_detail_url }')\n",
    "            return\n",
    "\n",
    "        # ２回以上来訪してコメントしているユーザは最新の1件のみを採用\n",
    "        #<div class=\"rvw-item__rvw-comment\" property=\"v:description\">\n",
    "        #  <p>\n",
    "        #    <br>すごい煮干しラーメン凪 新宿ゴールデン街本館<br>スーパーゴールデン1600円（20食限定）を喰らう<br>大盛り無料です<br>スーパーゴールデンは、新宿ゴールデン街にちなんで、ココ本店だけの特別メニューだそうです<br>相方と歌舞伎町のtohoシネマズの映画館でドラゴンボール超ブロリー を観てきた<br>ブロリー 強すぎるね(^^)面白かったです<br>凪の煮干しラーメンも激ウマ<br>いったん麺ちゅるちゅる感に、レアチャーと大トロチャーシューのトロけ具合もうめえ<br>煮干しスープもさすが！と言うほど完成度が高い<br>さすが食べログラーメン百名店<br>と言うか<br>2日連チャンで、近場の食べログラーメン百名店のうちの2店舗、昨日の中華そば葉山さんと今日の凪<br>静岡では考えられん笑笑<br>ごちそうさまでした\n",
    "        #  </p>\n",
    "        #</div>\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        review = soup.find_all('div', class_='rvw-item__rvw-comment')#reviewが含まれているタグの中身をすべて取得\n",
    "        if len(review) == 0:\n",
    "            review = ''\n",
    "        else:\n",
    "            review = review[0].p.text.strip() # strip()は改行コードを除外する関数\n",
    "\n",
    "        #print('\\t\\t口コミテキスト：', review)\n",
    "        self.review = review\n",
    "\n",
    "        # データフレームの生成\n",
    "        self.make_df()\n",
    "        return\n",
    "\n",
    "    def make_df(self):\n",
    "        self.store_id = str(self.store_id_num).zfill(8) #0パディング\n",
    "        se = pd.Series([self.store_id, self.store_name, self.score, self.ward, self.review_cnt, self.review], self.columns) # 行を作成\n",
    "        self.df = self.df.append(se, self.columns) # データフレームに行を追加\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17bb86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1→店名：イデミスギノ  評価点数：3.99点  レビュー件数：1700 .   取得時間：78.70359182357788\n",
      "2→店名：パティスリー・パリセヴェイユ  評価点数：3.98点  レビュー件数：1279 .   取得時間：59.0174560546875\n",
      "3→店名：パティスリー プレジール  評価点数：3.95点  レビュー件数：357 .   取得時間：36.000511169433594\n",
      "4→店名：エーグルドゥース  評価点数：3.94点  レビュー件数：1115 .   取得時間：60.175503730773926\n",
      "5→店名：ブーランジェリー スドウ  評価点数：3.94点  レビュー件数：473 .   取得時間：60.54700183868408\n",
      "6→店名：オーボンヴュータン 尾山台店  評価点数：3.93点  レビュー件数：482 .   取得時間：58.861289978027344\n",
      "7→店名：LESS  評価点数：3.93点  レビュー件数：190 .   取得時間：34.92601990699768\n",
      "8→店名：レピキュリアン  評価点数：3.91点  レビュー件数：453 .   取得時間：45.17689490318298\n",
      "9→店名：クリオロ 東京本店  評価点数：3.91点  レビュー件数：425 .   取得時間：106.42064809799194\n",
      "10→店名：PATISSERIE ASAKO IWAYANAGI  評価点数：3.89点  レビュー件数：576 .   取得時間：76.30304718017578\n",
      "11→店名：パティスリー　ジュンウジタ  評価点数：3.89点  レビュー件数：264 .   取得時間：37.38649010658264\n",
      "12→店名：マテリエル  評価点数：3.88点  レビュー件数：326 .   取得時間：41.52122712135315\n",
      "13→店名：チクテベーカリー  評価点数：3.88点  レビュー件数：212 .   取得時間：36.33597683906555\n",
      "14→店名：ピエール・エルメ・パリ Aoyama  評価点数：3.86点  レビュー件数：861 .   取得時間：50.99441885948181\n",
      "15→店名：ショコラティエ パレ ド オール 東京  評価点数：3.86点  レビュー件数：675 .   取得時間：46.37573599815369\n",
      "16→店名：パティスリィ　ドゥ・ボン・クーフゥ 武蔵小山本店  評価点数：3.86点  レビュー件数：420 .   取得時間：62.965006828308105\n",
      "17→店名：リュードパッシー  評価点数：3.85点  レビュー件数：399 .   取得時間：46.61719298362732\n",
      "18→店名：ラ･メゾン･デュ･ショコラ 丸の内店  評価点数：3.84点  レビュー件数：691 .   取得時間：50.48578381538391\n",
      "19→店名：ル・プチメック 日比谷店  評価点数：3.84点  レビュー件数：678 .   取得時間：90.36618685722351\n",
      "20→店名：リベルターブル 赤坂店  評価点数：3.83点  レビュー件数：504 .   取得時間：75.60366082191467\n",
      "21→店名：マルイチベーグル  評価点数：3.82点  レビュー件数：1053 .   取得時間：46.816818952560425\n",
      "22→店名：ラデュレ サロン・ド・テ 銀座三越店  評価点数：3.82点  レビュー件数：951 .   取得時間：47.61697196960449\n",
      "23→店名：アトリエコータ 神楽坂店  評価点数：3.81点  レビュー件数：631 .   取得時間：101.41454792022705\n",
      "24→店名：ジェラテリア シンチェリータ  評価点数：3.81点  レビュー件数：477 .   取得時間：62.5560576915741\n",
      "25→店名：アディクト オ シュクル  評価点数：3.81点  レビュー件数：274 .   取得時間：38.580353021621704\n",
      "26→店名：VIRON 丸の内店  評価点数：3.80点  レビュー件数：1034 .   取得時間：56.86196303367615\n",
      "27→店名：リベルテ・パティスリー・ブーランジェリー 東京本店・吉祥寺  評価点数：3.80点  レビュー件数：345 .   取得時間：34.299763917922974\n",
      "28→店名：西洋菓子 しろたえ  評価点数：3.79点  レビュー件数：1269 .   取得時間：78.7289559841156\n",
      "29→店名：たいやき わかば  評価点数：3.79点  レビュー件数：1214 .   取得時間：140.71766805648804\n",
      "30→店名：パンとエスプレッソと  評価点数：3.79点  レビュー件数：1211 .   取得時間：72.74865674972534\n",
      "31→店名：ポワンエリーニュ  評価点数：3.79点  レビュー件数：1160 .   取得時間：158.8218321800232\n",
      "32→店名：ポワンタージュ  評価点数：3.79点  レビュー件数：749 .   取得時間：44.696083068847656\n",
      "33→店名：マンダリンバー  評価点数：3.79点  レビュー件数：231 .   取得時間：37.25863003730774\n",
      "34→店名：ラ ブティック ドゥ ジョエル・ロブション 丸の内ブリックスクエア店  評価点数：3.78点  レビュー件数：838 .   取得時間：45.501046895980835\n",
      "35→店名：ハリッツ 上原店  評価点数：3.78点  レビュー件数：677 .   取得時間：44.877540826797485\n",
      "36→店名：フルーツパーラーフクナガ  評価点数：3.78点  レビュー件数：653 . "
     ]
    }
   ],
   "source": [
    "tokyo_ramen_review = Tabelog(base_url=\"https://tabelog.com/tokyo/rstLst/cafe/\",test_mode=False, p_ward='東京都内')\n",
    "#CSV保存\n",
    "tokyo_ramen_review.df.to_csv(\"../output/tokyo_cafe_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4d751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
